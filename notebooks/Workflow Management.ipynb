{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Management\n",
    "\n",
    "Development and testing of the workflow management classes and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from dataclasses import dataclass, field, asdict, replace\n",
    "from dataclasses import fields as dcf\n",
    "\n",
    "import pint\n",
    "import click\n",
    "import petl as etl\n",
    "import marshmallow_dataclass\n",
    "from marshmallow_dataclass import class_schema\n",
    "from marshmallow import Schema, fields, EXCLUDE, INCLUDE, ValidationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_ESRI = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RainfallRaster:\n",
    "    \"\"\"store a reference to a NOAA Rainfall raster\n",
    "    \"\"\"\n",
    "\n",
    "    path: str = None\n",
    "    freq: int = None\n",
    "    ext: str = None\n",
    "\n",
    "RainfallRasterSchema = class_schema(RainfallRaster)\n",
    "\n",
    "\n",
    "class RainfallRasterConfig():\n",
    "    \"\"\"store rainfall download metadata with methods for portability\n",
    "    \"\"\"\n",
    "\n",
    "    root: str = None\n",
    "    rasters: List[RainfallRaster] = field(default_factory=[])\n",
    "\n",
    "    # def __init__(self, path):\n",
    "    #     self.path = Path(path)\n",
    "    #     self.lookup_table = []\n",
    "\n",
    "    # def as_dict(self):\n",
    "    #     return {\n",
    "    #         'path': str(self.path),\n",
    "    #         'lookup_table': self.lookup_table\n",
    "    #     }\n",
    "\n",
    "    # def as_json(self, out_path):\n",
    "    #     with open(out_path, 'w') as fp:\n",
    "    #         json.dump(self.as_dict(), fp)\n",
    "\n",
    "    # def as_csv(self, out_path):\n",
    "    #     etl.tocsv(etl.fromdicts(self.lookup_table), out_path)\n",
    "\n",
    "RainfallRasterConfigSchema = class_schema(RainfallRasterConfig)\n",
    "\n",
    "@dataclass\n",
    "class Precips:\n",
    "    \"\"\"Precipitation frequencies\n",
    "    \"\"\"\n",
    "    f1: float = None\n",
    "    f2: float = None\n",
    "    f5: float = None\n",
    "    f10: float = None\n",
    "    f25: float = None\n",
    "    f50: float = None\n",
    "    f100: float = None\n",
    "    f200: float = None\n",
    "    f500: float = None\n",
    "    f1000: float = None\n",
    "\n",
    "PrecipsSchema = marshmallow_dataclass.class_schema(Precips)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NaaccPoint:\n",
    "    \"\"\"NAACC model for a single culvert.\n",
    "    \n",
    "    NOTE: this is only a subset of available NAACC fields\n",
    "    \"\"\"\n",
    "\n",
    "    Survey_Id: str = None # 'field_short': 'Survey_ID'\n",
    "    Naacc_Culvert_Id: str = None # 'field_short': 'NAACC_ID'\n",
    "\n",
    "    Number_Of_Culverts: int = 1 # 'field_short': 'Flags'\n",
    "\n",
    "    Road: str = None # 'field_short': 'Rd_Name'\n",
    "    Material: str = None # 'field_short': 'Culv_Mat'\n",
    "    Inlet_Type: str = None # 'field_short': 'In_Type'\n",
    "    Inlet_Structure_Type: str = None # 'field_short': 'In_Shape'\n",
    "\n",
    "    Inlet_Width: float = None # 'field_short': 'In_A'\n",
    "    Inlet_Height: float = None # 'field_short': 'In_B'\n",
    "    Road_Fill_Height: float = None # 'field_short': 'HW'\n",
    "    Slope_Percent: float = None # 'field_short': 'Slope'\n",
    "    Crossing_Structure_Length: float = None # 'field_short': 'Length'\n",
    "    Outlet_Structure_Type: float = None # 'field_short': 'Out_Shape'\n",
    "    Outlet_Width: float = None # 'field_short': 'Out_A'\n",
    "    Outlet_Height: float = None # 'field_short': 'Out_B'\n",
    "    Crossing_Type: float = None # 'field_short': 'Crossing_Type'\n",
    "    Crossing_Comment: float = None # 'field_short': 'Comments'\n",
    "\n",
    "    GIS_Latitude: float = None # 'field_short': 'Lat'\n",
    "    GIS_Longitude: float = None # 'field_short': 'Long'\n",
    "\n",
    "NaaccPointSchema = marshmallow_dataclass.class_schema(NaaccPoint)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Basin:\n",
    "    \"\"\"Base model for characteristics of a single basin, including\n",
    "    characteristics of the outlet (point) and catchment (polygon) used for \n",
    "    analysis\n",
    "    \"\"\"\n",
    "    # unique id field, derived from the basin outlet point; AKA the \n",
    "    # pour_point_field. For NAACC-based culvert modeling, this is the\n",
    "    # NAACC Naacc_Culvert_Id field\n",
    "    cid: str = None\n",
    "    # group id field. non-unique ID field that indicates groups of related\n",
    "    # outlets. Used primarily for NAACC-based culvert modeling, this is the\n",
    "    # NAACC Survey_Id field\n",
    "    gid: str = None\n",
    "\n",
    "    # characteristics used for calculating peak flow\n",
    "    area_sqkm: float = None# <area of inlet's catchment in square km>\n",
    "    avg_slope_pct: float = None # <average slope of DEM in catchment>\n",
    "    avg_cn: float = None # <average curve number in the catchment>\n",
    "    max_fl: float = None # <maximum flow length in the catchment>\n",
    "    precip_table: Precips = Precips # <basin-specific precipitation estimates>\n",
    "\n",
    "    # geometries\n",
    "    inlet_geom: str = None\n",
    "    basin_geom: str = None\n",
    "    \n",
    "    # for recording the location of intermediate outputs\n",
    "    basin_polygon_filepath: str = None\n",
    "    basin_raster_filepath: str = None\n",
    "    \n",
    "\n",
    "BasinSchema = marshmallow_dataclass.class_schema(Basin)\n",
    "\n",
    "\n",
    "class RainfallRasterConfig():\n",
    "    \"\"\"store rainfall download metadata with methods for portability\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = Path(path)\n",
    "        self.lookup_table = []\n",
    "\n",
    "    def as_dict(self):\n",
    "        return {\n",
    "            'path': str(self.path),\n",
    "            'lookup_table': self.lookup_table\n",
    "        }\n",
    "\n",
    "    def as_json(self, out_path):\n",
    "        with open(out_path, 'w') as fp:\n",
    "            json.dump(self.as_dict(), fp)\n",
    "\n",
    "    def as_csv(self, out_path):\n",
    "        etl.tocsv(etl.fromdicts(self.lookup_table), out_path)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WorkflowConfig:\n",
    "    \"\"\"Store all parameters required for any of our model runs.\n",
    "    \"\"\"\n",
    "\n",
    "    # directories\n",
    "    work_dir: str = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # input points (culverts or catch-basins)\n",
    "\n",
    "    points_filepath: str = None\n",
    "    points_id_fieldname: str = None\n",
    "    is_naacc: bool = False\n",
    "    \n",
    "    # -----------------------------\n",
    "    # input landscape rasters\n",
    "\n",
    "    raster_dem_filepath: str = None\n",
    "    raster_flowdir_filepath: str = None\n",
    "    raster_slope_filepath: str = None\n",
    "    raster_curvenumber_filepath: str = None\n",
    "    raster_watershed_filepath: str = None\n",
    "\n",
    "    # --------------------------\n",
    "    # input rainfall\n",
    "\n",
    "    precip_src_config_filepath: str = None\n",
    "    precip_noaa_csv_filepath: str = None\n",
    "\n",
    "    # --------------------------\n",
    "    # outputs\n",
    "    output_points_filepath: str = None\n",
    "    output_basins_filepath: str = None\n",
    "\n",
    "    # --------------------------\n",
    "    # models for intermediate data\n",
    "\n",
    "    culverts: List[NaaccPoint] = field(default_factory=list)\n",
    "    basins: List[Basin] = field(default_factory=list)\n",
    "\n",
    "    # --------------------------\n",
    "    # analysis parameters\n",
    "    \n",
    "    area_conv_factor: float = 0.00000009290304\n",
    "    leng_conv_factor: float = 1\n",
    "    basins_simplify: bool = False\n",
    "\n",
    "WorkflowConfigSchema = marshmallow_dataclass.class_schema(WorkflowConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeakFlow01Schema(Schema):\n",
    "\n",
    "    points_filepath = fields.Str(required=True) # inlets\n",
    "    points_id_fieldname = fields.Str(required=True) # pour_point_field\n",
    "    raster_curvenumber_filepath = fields.Str(required=True) # cn_raster\n",
    "    precip_src_config_filepath = fields.Str(required=True) # precip_data\n",
    "    raster_dem_filepath = fields.Str(required=True)\n",
    "    basins_in_series = fields.Bool(default=True)\n",
    "\n",
    "    output_points_filepath = fields.Str(required=True) # output\n",
    "    output_basins_filepath = fields.Str() # output_catchments\n",
    "    \n",
    "    class Meta:\n",
    "        unknown = EXCLUDE    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowManager():\n",
    "    \"\"\"Base class for all workflows. Provides methods for storing and \n",
    "    persisting results from various workflow components.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        use_esri=USE_ESRI, \n",
    "        config_json_filepath=None, \n",
    "        rainfall_raster_json_filepath=None, \n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        # initialize an empty WorkflowConfig object with default values\n",
    "        self.config = WorkflowConfig()\n",
    "        #click.echo(self.config)\n",
    "\n",
    "        # if any confile files provided, load here. This will replace the\n",
    "        # config object entirely\n",
    "        self.config_json_filepath = config_json_filepath\n",
    "        self.rainfall_raster_json_filepath = rainfall_raster_json_filepath\n",
    "        self.load()\n",
    "        #click.echo(self.config)\n",
    "        \n",
    "        # regardless of what happens above, we have a config object. Now we\n",
    "        # use the provided keyword arguments to update it, overriding any that\n",
    "        # were provided in the JSON file.\n",
    "        self.config = replace(self.config, **kwargs)\n",
    "        # (individual workflows that subclass WorkflowManager handle whether or \n",
    "        # not the needed kwargs are actually present)\n",
    "        #click.echo(self.config)\n",
    "\n",
    "        # self.schema = WorkflowConfigSchema().load(**kwargs)\n",
    "\n",
    "        self.rainfall_config = None\n",
    "        \n",
    "        self.using_esri = use_esri\n",
    "        self.using_wbt = not use_esri\n",
    "\n",
    "        self.units = pint.UnitRegistry()\n",
    "\n",
    "    \n",
    "    def save(self, config_json_filepath):\n",
    "        \"\"\"Save workflow config to JSON.\n",
    "\n",
    "        Note that validation via WorkflowConfigSchema will only fail\n",
    "        if our code is doing something wrong.\n",
    "        \"\"\"\n",
    "\n",
    "        self.config_json_filepath = Path(config_json_filepath)\n",
    "\n",
    "        c = WorkflowConfigSchema().dump(asdict(self.config))\n",
    "        with open(config_json_filepath, 'w') as fp:\n",
    "            json.dump(c, fp)\n",
    "\n",
    "\n",
    "    def load(self, config_json_filepath=None, rainfall_raster_json_filepath=None):\n",
    "        \"\"\"load a workflow from a JSON file\n",
    "        \n",
    "        Note that validation via WorkflowConfigSchema will fail if the JSON has \n",
    "        been manually changed outside in a way that doesn't follow the schema\n",
    "        (i.e., it has to serialize correctly to load)\n",
    "        \"\"\"\n",
    "        click.echo(\"loading...\")\n",
    "\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Workflow Config\n",
    "\n",
    "        # select the file path ref to load. defaults to arg, fallsback to \n",
    "        # instance variable\n",
    "\n",
    "        cjf=None\n",
    "        if config_json_filepath:\n",
    "            cjf = config_json_filepath\n",
    "            self.config_json_filepath = cjf\n",
    "        elif self.config_json_filepath:\n",
    "            cjf = self.config_json_filepath\n",
    "\n",
    "        # reads from disk, validates, and stores\n",
    "        if cjf:\n",
    "            click.echo(\"Reading config from JSON file\")\n",
    "            with open(cjf) as fp:\n",
    "                config_as_dict = json.load(fp)\n",
    "            self.config = WorkflowConfigSchema().load(config_as_dict)\n",
    "\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Rainfall Raster Config\n",
    "\n",
    "        # select the file path ref to load. defaults to arg, fallsback to \n",
    "        # instance variable\n",
    "\n",
    "        rrj = None\n",
    "        if rainfall_raster_json_filepath:\n",
    "            rrj = rainfall_raster_json_filepath\n",
    "            self.rainfall_raster_json_filepath = rrj\n",
    "        elif self.rainfall_raster_json_filepath:\n",
    "            rrj = self.rainfall_raster_json_filepath\n",
    "\n",
    "        # reads from disk, validates, and stores\n",
    "\n",
    "        if rrj:\n",
    "            click.echo(\"Reading rainfall config from JSON file\")\n",
    "            with open(rrj) as fp:\n",
    "                rainfall_config_as_dict = json.load(fp) \n",
    "                self.rainfall_config = RainfallRasterConfigSchema().load(rainfall_config_as_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeakFlowCore(WorkflowManager):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        rainfall_raster_json_filepath,\n",
    "        save_config_json_filepath=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Core Peak Flow workflow.\n",
    "\n",
    "        :param save_config_json_filepath: save workflow config to a file, defaults to None\n",
    "        :type save_config_json_filepath: str, optional\n",
    "        :param kwargs: relevant properties in the WorkflowConfig object\n",
    "        :type kwargs: kwargs, optional \n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        self.save_config_json_filepath = save_config_json_filepath\n",
    "        self.load(rainfall_raster_json_filepath=rainfall_raster_json_filepath)\n",
    "    \n",
    "    def run_core_workflow(self):\n",
    "        print(\"running Peak Flow analysis\")\n",
    "        \n",
    "        as_d = WorkflowConfigSchema().dump(asdict(self.config))\n",
    "        # print(as_d)\n",
    "\n",
    "        # initialize the GP object with the config variables\n",
    "        print(\"initialize the GP object with the config variables\")\n",
    "\n",
    "        # read in precipitation data\n",
    "        print(\"read in precipitation data\")\n",
    "        \n",
    "        # delineate watersheds\n",
    "        print(\"delineate watersheds (as needed)\")\n",
    "\n",
    "        # derive data from catchments\n",
    "        print(\"derive parameters from basins\")\n",
    "\n",
    "        # calculate peak flow (t of c and flow per return period)\n",
    "        print(\"calculate peak flow\")\n",
    "\n",
    "        # save the config\n",
    "        if self.save_config_json_filepath:\n",
    "            self.save(self.save_config_json_filepath)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeakFlow01(PeakFlowCore):\n",
    "    \"\"\"Peak flow calculator; derives needed rasters from the DEM.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.run_core_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test config i/o with the peak flow workflow manager\n",
    "\n",
    "Some test kwargs. In practice these would come through from an ArcToolbox tool via a `sys.arg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kwargs={\n",
    "    'rainfall_raster_json_filepath': r\"C:\\Users\\chris\\dev\\drainage\\drainit\\tests\\rainfall_config_example.json\",\n",
    "    'raster_watershed_filepath': 'raster_watershed_filepath', \n",
    "    'culverts': [], \n",
    "    'precip_noaa_csv_filepath': 'precip_noaa_csv_filepath', \n",
    "    'raster_curvenumber_filepath': 'raster_curvenumber_filepath', \n",
    "    'is_naacc': True, \n",
    "    'points_id_fieldname': 'points_id_fieldname', \n",
    "    'work_dir': 'work_dir', \n",
    "    'output_basins_filepath': 'output_basins_filepath', \n",
    "    'raster_flowdir_filepath': 'raster_flowdir_filepath', \n",
    "    'precip_src_config_filepath': 'precip_src_config_filepath', \n",
    "    'output_points_filepath': 'output_points_filepath', \n",
    "    'points_filepath': 'points_filepath', \n",
    "    'basins': [],\n",
    "    'area_conv_factor': 9.290304e-08, \n",
    "    'leng_conv_factor': 100.0, \n",
    "    'basins_simplify': True, \n",
    "    'raster_dem_filepath': 'raster_dem_filepath', \n",
    "    'raster_slope_filepath': 'raster_slope_filepath'    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice we'd take the positional args that come through from the ArcToolbox tool python script a put them in the right kwargs to instantiate the class here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "loading...\n",
      "Reading rainfall config from JSON file\n",
      "running Peak Flow analysis\n",
      "initialize the GP object with the config variables\n",
      "read in precipitation data\n",
      "delineate watersheds (as needed)\n",
      "derive parameters from basins\n",
      "calculate peak flow\n"
     ]
    }
   ],
   "source": [
    "p = PeakFlow01(**test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorkflowConfig(work_dir='work_dir', points_filepath='points_filepath', points_id_fieldname='points_id_fieldname', is_naacc=True, raster_dem_filepath='raster_dem_filepath', raster_flowdir_filepath='raster_flowdir_filepath', raster_slope_filepath='raster_slope_filepath', raster_curvenumber_filepath='raster_curvenumber_filepath', raster_watershed_filepath='raster_watershed_filepath', precip_src_config_filepath='precip_src_config_filepath', precip_noaa_csv_filepath='precip_noaa_csv_filepath', output_points_filepath='output_points_filepath', output_basins_filepath='output_basins_filepath', culverts=[], basins=[], area_conv_factor=9.290304e-08, leng_conv_factor=100.0, basins_simplify=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RainfallRasterConfig(root='D:\\\\Dropbox (CivicMapper)\\\\Projects\\\\202004-02 Cornell Modeling\\\\3 - Production\\\\tool outputs\\\\c19 tests\\\\noaa_rainfall_2', rasters=[RainfallRaster(path='orb1yr24ha.asc', freq=1, ext='.asc'), RainfallRaster(path='orb1yr24ha.prj', freq=1, ext='.prj'), RainfallRaster(path='orb1yr24ha.xml', freq=1, ext='.xml'), RainfallRaster(path='orb2yr24ha.asc', freq=2, ext='.asc'), RainfallRaster(path='orb2yr24ha.prj', freq=2, ext='.prj'), RainfallRaster(path='orb2yr24ha.xml', freq=2, ext='.xml'), RainfallRaster(path='orb5yr24ha.asc', freq=5, ext='.asc'), RainfallRaster(path='orb5yr24ha.prj', freq=5, ext='.prj'), RainfallRaster(path='orb5yr24ha.xml', freq=5, ext='.xml'), RainfallRaster(path='orb10yr24ha.asc', freq=10, ext='.asc'), RainfallRaster(path='orb10yr24ha.prj', freq=10, ext='.prj'), RainfallRaster(path='orb10yr24ha.xml', freq=10, ext='.xml'), RainfallRaster(path='orb25yr24ha.asc', freq=25, ext='.asc'), RainfallRaster(path='orb25yr24ha.prj', freq=25, ext='.prj'), RainfallRaster(path='orb25yr24ha.xml', freq=25, ext='.xml'), RainfallRaster(path='orb50yr24ha.asc', freq=50, ext='.asc'), RainfallRaster(path='orb50yr24ha.prj', freq=50, ext='.prj'), RainfallRaster(path='orb50yr24ha.xml', freq=50, ext='.xml'), RainfallRaster(path='orb100yr24ha.asc', freq=100, ext='.asc'), RainfallRaster(path='orb100yr24ha.prj', freq=100, ext='.prj'), RainfallRaster(path='orb100yr24ha.xml', freq=100, ext='.xml'), RainfallRaster(path='orb200yr24ha.asc', freq=200, ext='.asc'), RainfallRaster(path='orb200yr24ha.prj', freq=200, ext='.prj'), RainfallRaster(path='orb200yr24ha.xml', freq=200, ext='.xml'), RainfallRaster(path='orb500yr24ha.asc', freq=500, ext='.asc'), RainfallRaster(path='orb500yr24ha.prj', freq=500, ext='.prj'), RainfallRaster(path='orb500yr24ha.xml', freq=500, ext='.xml'), RainfallRaster(path='orb1000yr24ha.asc', freq=1000, ext='.asc'), RainfallRaster(path='orb1000yr24ha.prj', freq=1000, ext='.prj'), RainfallRaster(path='orb1000yr24ha.xml', freq=1000, ext='.xml')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.rainfall_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(r\"C:\\Users\\chris\\dev\\drainage\\drainit\\tests\\config_example.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow-specific validation\n",
    "\n",
    "Passing all properties from the Workflow Config, validating only what is specified for the workflow-specific schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raster_curvenumber_filepath': 'raster_curvenumber_filepath',\n",
       " 'points_id_fieldname': 'points_id_fieldname',\n",
       " 'output_basins_filepath': 'output_basins_filepath',\n",
       " 'precip_src_config_filepath': 'precip_src_config_filepath',\n",
       " 'output_points_filepath': 'output_points_filepath',\n",
       " 'points_filepath': 'points_filepath',\n",
       " 'raster_dem_filepath': 'raster_dem_filepath'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = PeakFlow01Schema().load(asdict(p.config))\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When passing not enough kwargs passed it, throws error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing parameters!\n",
      " {'raster_dem_filepath': ['Missing data for required field.']}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    params = PeakFlow01Schema().load({\n",
    "        'raster_curvenumber_filepath': 'raster_curvenumber_filepath',\n",
    "        'points_id_fieldname': 'points_id_fieldname',\n",
    "        'output_basins_filepath': 'output_basins_filepath',\n",
    "        'precip_src_config_filepath': 'precip_src_config_filepath',\n",
    "        'output_points_filepath': 'output_points_filepath',\n",
    "        'points_filepath': 'points_filepath'\n",
    "        #'raster_dem_filepath': 'raster_dem_filepath'\n",
    "    })\n",
    "    params\n",
    "except ValidationError as e:\n",
    "    print(\"Missing parameters!\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation without deserialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid schema!\n"
     ]
    }
   ],
   "source": [
    "errors = PeakFlow01Schema().validate(asdict(p.config))\n",
    "if errors:\n",
    "    print(\"Invalide schema\", errors)\n",
    "else:\n",
    "    print(\"Valid schema!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Peak Flow analysis\n",
      "initialize the GP object with the config variables\n",
      "read in precipitation data\n",
      "delineate watersheds (as needed)\n",
      "derive parameters from basins\n",
      "calculate peak flow\n"
     ]
    }
   ],
   "source": [
    "p.run_core_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Tester:\n",
    "    \n",
    "    attr1: float\n",
    "    attr2: float\n",
    "        \n",
    "    def adder(self):\n",
    "        if all([\n",
    "            self.attr1 is not None,\n",
    "            self.attr2 is not None\n",
    "        ]):\n",
    "            return self.attr1 + self.attr2\n",
    "        else:\n",
    "            print(\"set the attrs first\")\n",
    "            \n",
    "TesterSch = marshmallow_dataclass.class_schema(Tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = TesterSch().load(dict(attr1=1, attr2=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set the attrs first\n"
     ]
    }
   ],
   "source": [
    "x.adder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attr2': ['Missing data for required field.']}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TesterSch().validate(dict(attr1=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survey_Id',\n",
       " 'Naacc_Culvert_Id',\n",
       " 'Number_Of_Culverts',\n",
       " 'Road',\n",
       " 'Material',\n",
       " 'Inlet_Type',\n",
       " 'Inlet_Structure_Type',\n",
       " 'Inlet_Width',\n",
       " 'Inlet_Height',\n",
       " 'Road_Fill_Height',\n",
       " 'Slope_Percent',\n",
       " 'Crossing_Structure_Length',\n",
       " 'Outlet_Structure_Type',\n",
       " 'Outlet_Width',\n",
       " 'Outlet_Height',\n",
       " 'Crossing_Type',\n",
       " 'Crossing_Comment',\n",
       " 'GIS_Latitude',\n",
       " 'GIS_Longitude']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f.name for f in dcf(NaaccPoint)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
